MATH:
  URA-LLaMa 70B:
    EM: 0.00
    EM_std: 0.00
    F1: 0.12
    F1_std: 0.01
    Equ: 0.18
    Equ_std: 0.02
  URA-LLaMa 13B:
    EM: 0.00
    EM_std: 0.00
    F1: 0.23
    F1_std: 0.01
    Equ: 0.17
    Equ_std: 0.01
  URA-LLaMa 7B:
    EM: 0.00
    EM_std: 0.00
    F1: 0.23
    F1_std: 0.01
    Equ: 0.09
    Equ_std: 0.01
  LLaMa-2 13B:
    EM: 0.00
    EM_std: 0.00
    F1: 0.12
    F1_std: 0.01
    Equ: 0.18
    Equ_std: 0.02
  LLaMa-2 7B:
    EM: 0.00
    EM_std: 0.00
    F1: 0.10
    F1_std: 0.00
    Equ: 0.12
    Equ_std: 0.02
  Vietcuna 7B:
    EM: 0.00
    EM_std: 0.00
    F1: 0.13
    F1_std: 0.01
    Equ: 0.10
    Equ_std: 0.01
  MixSUra:
    EM: 0.00
    EM_std: 0.00
    F1: 0.17
    F1_std: 0.01
    Equ: 0.33
    Equ_std: 0.00
  GPT-3.5:
    EM: 0.00
    EM_std: 0.00
    F1: 0.32
    F1_std: 0.01
    Equ: 0.78
    Equ_std: 0.02
  GPT-4:
    EM: 0.00
    EM_std: 0.00
    F1: 0.32
    F1_std: 0.01
    Equ: 0.79
    Equ_std: 0.02