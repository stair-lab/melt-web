UiT-ViCTSD:
  URA-LLaMa 70B:
    AC: 0.44
    AC_std: 0.01
    F1: 0.27
    F1_std: 0.01
    AR: 0.75
    AR_std: 0.01
    ECE: 0.52
    ECE_std: 0.01
    A@10: 0.37
    A@10_std: 0.02
  URA-LLaMa 13B:
    AC: 0.44
    AC_std: 0.01
    F1: 0.30
    F1_std: 0.05
    AR: 0.67
    AR_std: 0.01
    ECE: 0.33
    ECE_std: 0.01
    A@10: 0.41
    A@10_std: 0.03
  URA-LLaMa 7B:
    AC: 0.43
    AC_std: 0.01
    F1: 0.40
    F1_std: 0.01
    AR: 0.60
    AR_std: 0.01
    ECE: 0.29
    ECE_std: 0.01
    A@10: 0.71
    A@10_std: 0.02
  LLaMa-2 13B:
    AC: 0.28
    AC_std: 0.01
    F1: 0.19
    F1_std: 0.00
    AR: 0.67
    AR_std: 0.01
    ECE: 0.52
    ECE_std: 0.01
    A@10: 0.63
    A@10_std: 0.03
  LLaMa-2 7B:
    AC: 0.16
    AC_std: 0.01
    F1: 0.12
    F1_std: 0.01
    AR: 0.61
    AR_std: 0.01
    ECE: 0.66
    ECE_std: 0.01
    A@10: 0.08
    A@10_std: 0.02
  Vietcuna 7B:
    AC: 0.08
    AC_std: 0.00
    F1: 0.10
    F1_std: 0.01
    AR: 0.50
    AR_std: 0.00
    ECE: 0.42
    ECE_std: 0.00
    A@10: 0.08
    A@10_std: 0.03
  MixSUra:
    AC: 0.70
    AC_std: null
    F1: 0.39
    F1_std: null
    AR: null
    AR_std: null
    ECE: 0.29
    ECE_std: null
    A@10: 0.80
    A@10_std: null
  GPT-3.5:
    AC: 0.63
    AC_std: 0.02
    F1: 0.54
    F1_std: 0.02
    AR: null
    AR_std: null
    ECE: 0.13
    ECE_std: 0.02
    A@10: 0.63
    A@10_std: 0.05
  GPT-4:
    AC: 0.89
    AC_std: 0.00
    F1: 0.71
    F1_std: 0.01
    AR: null
    AR_std: null
    ECE: 0.39
    ECE_std: 0.00
    A@10: 0.89
    A@10_std: 0.03
UiT-ViHSD:
  URA-LLaMa 70B:
    AC: 0.17
    AC_std: 0.00
    F1: 0.15
    F1_std: 0.00
    AR: 0.64
    AR_std: 0.01
    ECE: 0.57
    ECE_std: 0.00
    A@10: 0.27
    A@10_std: 0.02
  URA-LLaMa 13B:
    AC: 0.26
    AC_std: 0.01
    F1: 0.16
    F1_std: 0.00
    AR: 0.61
    AR_std: 0.01
    ECE: 0.42
    ECE_std: 0.01
    A@10: 0.21
    A@10_std: 0.02
  URA-LLaMa 7B:
    AC: 0.16
    AC_std: 0.00
    F1: 0.10
    F1_std: 0.00
    AR: 0.67
    AR_std: 0.01
    ECE: 0.32
    ECE_std: 0.00
    A@10: 0.28
    A@10_std: 0.02
  LLaMa-2 13B:
    AC: 0.17
    AC_std: 0.00
    F1: 0.11
    F1_std: 0.00
    AR: 0.62
    AR_std: 0.01
    ECE: 0.58
    ECE_std: 0.00
    A@10: 0.44
    A@10_std: 0.02
  LLaMa-2 7B:
    AC: 0.01
    AC_std: 0.00
    F1: 0.01
    F1_std: 0.00
    AR: 0.56
    AR_std: 0.01
    ECE: 0.71
    ECE_std: 0.00
    A@10: 0.01
    A@10_std: 0.02
  Vietcuna 7B:
    AC: 0.61
    AC_std: 0.01
    F1: 0.21
    F1_std: 0.00
    AR: 0.50
    AR_std: 0.00
    ECE: 0.28
    ECE_std: 0.01
    A@10: 0.61
    A@10_std: 0.02
  MixSUra:
    AC: 0.58
    AC_std: null
    F1: 0.31
    F1_std: null
    AR: 0.68
    AR_std: null
    ECE: 0.30
    ECE_std: null
    A@10: 0.93
    A@10_std: null
  GPT-3.5:
    AC: 0.63
    AC_std: 0.01
    F1: 0.47
    F1_std: 0.01
    AR: null
    AR_std: null
    ECE: 0.29
    ECE_std: 0.01
    A@10: 0.63
    A@10_std: 0.02
  GPT-4:
    AC: 0.77
    AC_std: 0.01
    F1: 0.57
    F1_std: 0.01
    AR: null
    AR_std: null
    ECE: 0.44
    ECE_std: 0.01
    A@10: 0.77
    A@10_std: 0.02