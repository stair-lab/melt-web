UiT-VSMEC:
    URA-LLaMa 70B:
      AC: 0.25
      AC_std: 0.00
      F1: 0.16
      F1_std: 0.00
      AR: 0.56
      AR_std: 0.02
      ECE: 0.20
      ECE_std: 0.00
      A@10: 0.33
      A@10_std: 0.00
    URA-LLaMa 13B:
      AC: 0.30
      AC_std: 0.00
      F1: 0.11
      F1_std: 0.00
      AR: 0.51
      AR_std: 0.01
      ECE: 0.26
      ECE_std: 0.00
      A@10: 0.44
      A@10_std: 0.00
    URA-LLaMa 7B:
      AC: 0.29
      AC_std: 0.00
      F1: 0.10
      F1_std: 0.00
      AR: 0.57
      AR_std: 0.01
      ECE: 0.17
      ECE_std: 0.00
      A@10: 0.30
      A@10_std: 0.00
    LLaMa-2 13B:
      AC: 0.19
      AC_std: 0.00
      F1: 0.07
      F1_std: 0.00
      AR: 0.52
      AR_std: 0.01
      ECE: 0.47
      ECE_std: 0.00
      A@10: 0.43
      A@10_std: 0.00
    LLaMa-2 7B:
      AC: 0.17
      AC_std: 0.00
      F1: 0.10
      F1_std: 0.00
      AR: 0.55
      AR_std: 0.00
      ECE: 0.33
      ECE_std: 0.00
      A@10: 0.29
      A@10_std: 0.00
    Vietcuna 7B:
      AC: 0.09
      AC_std: 0.00
      F1: 0.09
      F1_std: 0.00
      AR: 0.51
      AR_std: 0.01
      ECE: 0.91
      ECE_std: 0.00
      A@10: 0.09
      A@10_std: 0.00
    MixSUra:
      AC: 0.35
      AC_std: null
      F1: 0.27
      F1_std: null
      AR: 0.70
      AR_std: null
      ECE: 0.58
      ECE_std: null
      A@10: 0.70
      A@10_std: null
    GPT-3.5:
      AC: 0.42
      AC_std: 0.00
      F1: 0.41
      F1_std: 0.00
      AR: null
      AR_std: null
      ECE: 0.28
      ECE_std: 0.00
      A@10: 0.30
      A@10_std: 0.00
    GPT-4:
      AC: 0.48
      AC_std: 0.00
      F1: 0.45
      F1_std: 0.00
      AR: null 
      AR_std: null
      ECE: 0.33
      ECE_std: 0.00
      A@10: 0.40
      A@10_std: 0.00
PhoATIS:
    URA-LLaMa 70B:
      AC: 0.16
      AC_std: 0.02
      F1: 0.26
      F1_std: 0.03
      AR: 0.79
      AR_std: 0.00
      ECE: 0.79
      ECE_std: 0.02
      A@10: 0.08
      A@10_std: 0.06
    URA-LLaMa 13B:
      AC: 0.01
      AC_std: 0.01
      F1: 0.05
      F1_std: 0.01
      AR: 0.47
      AR_std: 0.01
      ECE: 0.84
      ECE_std: 0.01
      A@10: 0.00
      A@10_std: 0.04
    URA-LLaMa 7B:
      AC: 0.02
      AC_std: 0.01
      F1: 0.04
      F1_std: 0.00
      AR: 0.55
      AR_std: 0.01
      ECE: 0.18
      ECE_std: 0.01
      A@10: 0.01
      A@10_std: 0.02
    LLaMa-2 13B:
      AC: 0.02
      AC_std: 0.00
      F1: 0.06
      F1_std: 0.00
      AR: 0.57
      AR_std: 0.01
      ECE: 0.91
      ECE_std: 0.00
      A@10: 0.01
      A@10_std: 0.00
    LLaMa-2 7B:
      AC: 0.01
      AC_std: 0.01
      F1: 0.00
      F1_std: 0.00
      AR: 0.56
      AR_std: 0.00
      ECE: 0.69
      ECE_std: 0.01
      A@10: 0.02
      A@10_std: 0.02
    Vietcuna 7B:
      AC: 0.02
      AC_std: 0.01
      F1: 0.01
      F1_std: 0.00
      AR: 0.55
      AR_std: 0.01
      ECE: 0.23
      ECE_std: 0.01
      A@10: 0.02
      A@10_std: 0.01
    MixSUra:
      AC: 0.80
      AC_std: null
      F1: 55
      F1_std: null
      AR: 0.94
      AR_std: null
      ECE: 0.15
      ECE_std: null
      A@10: 0.88
      A@10_std: null
    GPT-3.5:
      AC: 0.68
      AC_std: 0.02
      F1: 0.64
      F1_std: 0.03
      AR: null
      AR_std: null
      ECE: 0.62
      ECE_std: 0.02
      A@10: 0.70
      A@10_std: 0.05
    GPT-4:
      AC: 0.86
      AC_std: 0.01
      F1: 0.80
      F1_std: 0.02
      AR: null
      AR_std: null
      ECE: 0.80
      ECE_std: 0.01
      A@10: 0.91
      A@10_std: 0.03