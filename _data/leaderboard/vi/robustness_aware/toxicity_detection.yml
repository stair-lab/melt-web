UiT-ViCTSD:
    URA-LLaMa 70B:
      AC: 0.32
      AC_std: 0.00
      F1: 0.21
      F1_std: 0.00
      AR: 0.72
      AR_std: 0.01
      ECE: 0.62
      ECE_std: 0.00
      A@10: 0.33
      A@10_std: 0.00
    URA-LLaMa 13B:
      AC: 0.27
      AC_std: 0.00
      F1: 0.26
      F1_std: 0.00
      AR: 0.56
      AR_std: 0.00
      ECE: 0.56
      ECE_std: 0.00
      A@10: 0.12
      A@10_std: 0.00
    URA-LLaMa 7B:
      AC: 0.22
      AC_std: 0.00
      F1: 0.21
      F1_std: 0.00
      AR: 0.63
      AR_std: 0.00
      ECE: 0.39
      ECE_std: 0.00
      A@10: 0.36
      A@10_std: 0.00
    LLaMa-2 13B:
      AC: 0.12
      AC_std: 0.00
      F1: 0.11
      F1_std: 0.00
      AR: 0.56
      AR_std: 0.01
      ECE: 0.66
      ECE_std: 0.00
      A@10: 0.12
      A@10_std: 0.00
    LLaMa-2 7B:
      AC: 0.04
      AC_std: 0.00
      F1: 0.04
      F1_std: 0.00
      AR: 0.62
      AR_std: 0.00
      ECE: 0.86
      ECE_std: 0.00
      A@10: 0.02
      A@10_std: 0.00
    Vietcuna 7B:
      AC: 0.11
      AC_std: 0.00
      F1: 0.11
      F1_std: 0.00
      AR: 0.54
      AR_std: 0.00
      ECE: 0.39
      ECE_std: 0.00
      A@10: 0.13
      A@10_std: 0.00
    MixSUra:
      AC: 0.72
      AC_std: null
      F1: 0.39
      F1_std: null
      AR: null
      AR_std: null
      ECE: 0.25
      ECE_std: null
      A@10: 0.81
      A@10_std: null
    GPT-3.5:
      AC: 0.51
      AC_std: 0.00
      F1: 0.46
      F1_std: 0.00
      AR: 0.5
      AR_std: 0.00
      ECE: 0.01
      ECE_std: 0.00
      A@10: 0.54
      A@10_std: 0.00
    GPT-4:
      AC: 0.88
      AC_std: 0.00
      F1: 0.71
      F1_std: 0.00
      AR: null
      AR_std: null
      ECE: 0.38
      ECE_std: 0.00
      A@10: 0.88
      A@10_std: 0.00
UiT-ViHSD:
    URA-LLaMa 70B:
      AC: 0.14
      AC_std: 0.00
      F1: 0.12
      F1_std: 0.00
      AR: 0.64
      AR_std: 0.02
      ECE: 0.61
      ECE_std: 0.00
      A@10: 0.23
      A@10_std: 0.00
    URA-LLaMa 13B:
      AC: 0.18
      AC_std: 0.00
      F1: 0.11
      F1_std: 0.00
      AR: 0.57
      AR_std: 0.01
      ECE: 0.45
      ECE_std: 0.00
      A@10: 0.20
      A@10_std: 0.00
    URA-LLaMa 7B:
      AC: 0.12
      AC_std: 0.00
      F1: 0.07
      F1_std: 0.00
      AR: 0.62
      AR_std: 0.00
      ECE: 0.38
      ECE_std: 0.00
      A@10: 0.19
      A@10_std: 0.00
    LLaMa-2 13B:
      AC: 0.10
      AC_std: 0.00
      F1: 0.07
      F1_std: 0.00
      AR: 0.59
      AR_std: 0.01
      ECE: 0.62
      ECE_std: 0.00
      A@10: 0.24
      A@10_std: 0.00
    LLaMa-2 7B:
      AC: 0.01
      AC_std: 0.00
      F1: 0.00
      F1_std: 0.00
      AR: 0.54
      AR_std: 0.00
      ECE: 0.79
      ECE_std: 0.00
      A@10: 0.00
      A@10_std: 0.00
    Vietcuna 7B:
      AC: 0.09
      AC_std: 0.00
      F1: 0.05
      F1_std: 0.00
      AR: 0.5
      AR_std: 0.00
      ECE: 0.24
      ECE_std: 0.00
      A@10: 0.08
      A@10_std: 0.00
    MixSUra:
      AC: 0.66
      AC_std: null
      F1: 0.31
      F1_std: null
      AR: 0.67
      AR_std: null
      ECE: 0.21
      ECE_std: null
      A@10: 0.82
      A@10_std: null
    GPT-3.5:
      AC: 0.64
      AC_std: 0.00
      F1: 0.47
      F1_std: 0.00
      AR: null
      AR_std: null
      ECE: 0.30
      ECE_std: 0.00
      A@10: 0.63
      A@10_std: 0.00
    GPT-4:
      AC: 0.78
      AC_std: 0.00
      F1: 0.56
      F1_std: 0.00
      AR: null
      AR_std: null
      ECE: 0.44
      ECE_std: 0.00
      A@10: 0.78
      A@10_std: 0.00